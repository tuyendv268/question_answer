{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"nYV87aO_-TY1"},"outputs":[],"source":["#drive.mount('/content/drive')"]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UW6E36Bbgi8g","executionInfo":{"status":"ok","timestamp":1641716023933,"user_tz":-420,"elapsed":15979,"user":{"displayName":"Tuyen Duong Van","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjtTacBQ6s-40IAkPpB9UiqHRK4GYzu8VaLeAEr9g=s64","userId":"13283457235207767479"}},"outputId":"44f59e8b-63d7-4ae3-8f63-2f9f2f1dab2a"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","execution_count":2,"metadata":{"id":"ZVNa6Acd-bn8","executionInfo":{"status":"ok","timestamp":1641716034173,"user_tz":-420,"elapsed":8846,"user":{"displayName":"Tuyen Duong Van","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjtTacBQ6s-40IAkPpB9UiqHRK4GYzu8VaLeAEr9g=s64","userId":"13283457235207767479"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"98eedcb8-6a64-4aff-e829-6f49979651a2"},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting transformers\n","  Downloading transformers-4.15.0-py3-none-any.whl (3.4 MB)\n","\u001b[K     |████████████████████████████████| 3.4 MB 5.5 MB/s \n","\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n","Collecting pyyaml>=5.1\n","  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n","\u001b[K     |████████████████████████████████| 596 kB 36.3 MB/s \n","\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n","Collecting sacremoses\n","  Downloading sacremoses-0.0.46-py3-none-any.whl (895 kB)\n","\u001b[K     |████████████████████████████████| 895 kB 50.9 MB/s \n","\u001b[?25hRequirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.8.2)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.62.3)\n","Collecting huggingface-hub<1.0,>=0.1.0\n","  Downloading huggingface_hub-0.2.1-py3-none-any.whl (61 kB)\n","\u001b[K     |████████████████████████████████| 61 kB 495 kB/s \n","\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.4.0)\n","Collecting tokenizers<0.11,>=0.10.1\n","  Downloading tokenizers-0.10.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.3 MB)\n","\u001b[K     |████████████████████████████████| 3.3 MB 31.8 MB/s \n","\u001b[?25hRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (3.10.0.2)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.6)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.6.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.10.8)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n","Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.1.0)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n","Installing collected packages: pyyaml, tokenizers, sacremoses, huggingface-hub, transformers\n","  Attempting uninstall: pyyaml\n","    Found existing installation: PyYAML 3.13\n","    Uninstalling PyYAML-3.13:\n","      Successfully uninstalled PyYAML-3.13\n","Successfully installed huggingface-hub-0.2.1 pyyaml-6.0 sacremoses-0.0.46 tokenizers-0.10.3 transformers-4.15.0\n"]}],"source":["pip install transformers"]},{"cell_type":"code","execution_count":24,"metadata":{"id":"abBpymzdMAjb","executionInfo":{"status":"ok","timestamp":1641720122024,"user_tz":-420,"elapsed":4,"user":{"displayName":"Tuyen Duong Van","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjtTacBQ6s-40IAkPpB9UiqHRK4GYzu8VaLeAEr9g=s64","userId":"13283457235207767479"}}},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","import transformers\n","from transformers import AutoModel, AutoTokenizer\n","import torch\n","import torch.nn as nn\n","from torch.utils.data import Dataset\n","from torch.utils.data import DataLoader\n","import torch.optim as optim\n","import torch.nn.functional as F\n","import json\n","from tqdm import tqdm\n","from torch.nn.functional import one_hot\n","from sklearn.metrics import f1_score"]},{"cell_type":"markdown","source":["#Data preprocess"],"metadata":{"id":"S-NTNlMo-2Bw"}},{"cell_type":"code","source":["# xquad_vi_df = pd.read_json('/content/drive/MyDrive/Fine-Tune-Bert/data/_train_xquad_vi.json')"],"metadata":{"id":"5O7EQBwUh9lY"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# mlqa_df = pd.read_json('/content/drive/MyDrive/Fine-Tune-Bert/data/mlqa_trainingdata.json')"],"metadata":{"id":"UKm6dH0m0MkO"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# # convert mlqa format to zalo format\n","# datas = []\n","# i = 0\n","# for data in mlqa_df['data']:\n","#   for paragraph in data['paragraphs']:\n","#     for qas in paragraph['qas']:\n","#       temp_dict = {}\n","#       temp_dict['id'] = qas['id']\n","#       temp_dict['question'] = qas['question']\n","#       temp_dict['title'] = data['title']\n","#       temp_dict['context'] = paragraph['context']\n","#       temp_dict['label'] = True\n","#       i+=1\n","#       print(i)\n","#       datas.append(temp_dict)"],"metadata":{"id":"rDcwUSZm0XUa"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# with open('/content/mlqa_vi_zalo_format.json', 'w',encoding='utf-8') as outfile:\n","#      json.dump(datas, outfile,ensure_ascii=False,indent=4)"],"metadata":{"id":"mWWPxnDp3EZV"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# convert xquad format to zalo format\n","# xquad_vi_dict = {}\n","# datas = []\n","# i = 0\n","# for data in xquad_vi_df['data']:\n","#   for paragraph in data['paragraphs']:\n","#     for qas in paragraph['qas']:\n","#       temp_dict = {}\n","#       temp_dict['id'] = qas['id']\n","#       temp_dict['question'] = qas['question']\n","#       temp_dict['title'] = data['title']\n","#       temp_dict['context'] = paragraph['context']\n","#       temp_dict['label'] = True\n","      \n","#       datas.append(temp_dict)"],"metadata":{"id":"uCLJY9hOiGiR"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# with open('/content/xquad_vi_zalo_format.json', 'w',encoding='utf-8') as outfile:\n","#     json.dump(datas, outfile,ensure_ascii=False,indent=4)"],"metadata":{"id":"zkPaOOqzqvMX"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# zalodata_df = pd.read_json('/content/drive/MyDrive/Fine-Tune-Bert/data/zalo_dataset.json')"],"metadata":{"id":"rtbwMeye3dML"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# zalodata_df.shape"],"metadata":{"id":"da9m5vE9a0am"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# chia tập test lấy từ bộ dữ liệu của zalo\n","# with open('/content/drive/MyDrive/Fine-Tune-Bert/data/testing_zalodata.json', 'w') as file:\n","#     zalodata_df[0:3000].to_json(file, orient='records',force_ascii=False,indent=4)"],"metadata":{"id":"dSQWc9k-5o0r"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# with open('/content/drive/MyDrive/Fine-Tune-Bert/data/trainingdata_zalo.json', 'w') as file:\n","#     zalodata_df[3000:].to_json(file, orient='records',force_ascii=False,indent=4)"],"metadata":{"id":"x_8Kp-Uz6iN4"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#Train"],"metadata":{"id":"lpf8egIX-ywg"}},{"cell_type":"code","source":["# mlqadata_df = pd.read_json('/content/drive/MyDrive/Fine-Tune-Bert/data/mlqa_vi_zalo_format.json')\n","# xquaddata_df = pd.read_json('/content/drive/MyDrive/Fine-Tune-Bert/data/xquad_vi_zaloformat_training_data.json')\n","zalodata_df = pd.read_json('/content/drive/MyDrive/Fine-Tune-Bert/data/trainingdata_zalo.json')"],"metadata":{"id":"vJTCOX3D9AIv","executionInfo":{"status":"ok","timestamp":1641721231035,"user_tz":-420,"elapsed":349,"user":{"displayName":"Tuyen Duong Van","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjtTacBQ6s-40IAkPpB9UiqHRK4GYzu8VaLeAEr9g=s64","userId":"13283457235207767479"}}},"execution_count":50,"outputs":[]},{"cell_type":"code","source":["zalodata_df = zalodata_df.rename({'text':'context'},axis =1)"],"metadata":{"id":"GKXJw6nA91uH","executionInfo":{"status":"ok","timestamp":1641721232490,"user_tz":-420,"elapsed":2,"user":{"displayName":"Tuyen Duong Van","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjtTacBQ6s-40IAkPpB9UiqHRK4GYzu8VaLeAEr9g=s64","userId":"13283457235207767479"}}},"execution_count":51,"outputs":[]},{"cell_type":"code","source":["# trainingdata = pd.concat((zalodata_df,mlqadata_df,xquaddata_df))"],"metadata":{"id":"TdJ0KwQN9OwR","executionInfo":{"status":"ok","timestamp":1641721198550,"user_tz":-420,"elapsed":336,"user":{"displayName":"Tuyen Duong Van","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjtTacBQ6s-40IAkPpB9UiqHRK4GYzu8VaLeAEr9g=s64","userId":"13283457235207767479"}}},"execution_count":49,"outputs":[]},{"cell_type":"code","source":["# trainingdata.shape"],"metadata":{"id":"K11Tdcce9a5H","executionInfo":{"status":"ok","timestamp":1641716042167,"user_tz":-420,"elapsed":11,"user":{"displayName":"Tuyen Duong Van","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjtTacBQ6s-40IAkPpB9UiqHRK4GYzu8VaLeAEr9g=s64","userId":"13283457235207767479"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"9bffb263-5a1c-4b80-a669-ab99055801ad"},"execution_count":7,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(15859, 5)"]},"metadata":{},"execution_count":7}]},{"cell_type":"code","execution_count":8,"metadata":{"id":"pHtUtdEYO3WU","executionInfo":{"status":"ok","timestamp":1641716042167,"user_tz":-420,"elapsed":9,"user":{"displayName":"Tuyen Duong Van","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjtTacBQ6s-40IAkPpB9UiqHRK4GYzu8VaLeAEr9g=s64","userId":"13283457235207767479"}}},"outputs":[],"source":["# cuda = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"]},{"cell_type":"code","execution_count":52,"metadata":{"id":"1ITKUNKWQhSr","executionInfo":{"status":"ok","timestamp":1641721245808,"user_tz":-420,"elapsed":1962,"user":{"displayName":"Tuyen Duong Van","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjtTacBQ6s-40IAkPpB9UiqHRK4GYzu8VaLeAEr9g=s64","userId":"13283457235207767479"}}},"outputs":[],"source":["columns = [\"context\", 'question','label']\n","data = []\n","for index, row in zalodata_df.iterrows():\n","  temp = []\n","  temp.append(row['context'])\n","  temp.append(row['question'])\n","  temp.append(int(row['label']))\n","  data.append(temp)"]},{"cell_type":"code","execution_count":53,"metadata":{"id":"cGxftmPlUbew","executionInfo":{"status":"ok","timestamp":1641721249758,"user_tz":-420,"elapsed":3953,"user":{"displayName":"Tuyen Duong Van","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjtTacBQ6s-40IAkPpB9UiqHRK4GYzu8VaLeAEr9g=s64","userId":"13283457235207767479"}}},"outputs":[],"source":["phobert = AutoModel.from_pretrained(\"vinai/phobert-base\",output_hidden_states=True)\n","tokenizer = AutoTokenizer.from_pretrained(\"vinai/phobert-base\", use_fast=False)"]},{"cell_type":"code","execution_count":54,"metadata":{"id":"-Twy0-O1T_EN","executionInfo":{"status":"ok","timestamp":1641721250098,"user_tz":-420,"elapsed":3,"user":{"displayName":"Tuyen Duong Van","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjtTacBQ6s-40IAkPpB9UiqHRK4GYzu8VaLeAEr9g=s64","userId":"13283457235207767479"}}},"outputs":[],"source":["data = pd.DataFrame(data, columns=columns)"]},{"cell_type":"code","source":["data = data.sample(frac = 1)"],"metadata":{"id":"pLUksfdUElZk","executionInfo":{"status":"ok","timestamp":1641721250099,"user_tz":-420,"elapsed":3,"user":{"displayName":"Tuyen Duong Van","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjtTacBQ6s-40IAkPpB9UiqHRK4GYzu8VaLeAEr9g=s64","userId":"13283457235207767479"}}},"execution_count":55,"outputs":[]},{"cell_type":"code","execution_count":56,"metadata":{"id":"__WZDjD6MEKB","executionInfo":{"status":"ok","timestamp":1641721250100,"user_tz":-420,"elapsed":4,"user":{"displayName":"Tuyen Duong Van","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjtTacBQ6s-40IAkPpB9UiqHRK4GYzu8VaLeAEr9g=s64","userId":"13283457235207767479"}}},"outputs":[],"source":["class TextDataset(Dataset):\n","  def __init__(self, text, question, label, tokenizer, max_length):\n","    super(TextDataset, self).__init__()\n","    self.tokenizer = tokenizer\n","    self.text = text\n","    self.question = question\n","    self.label = label\n","    self.max_length = max_length\n","  def __len__(self):\n","    return len(self.label)\n","  def __getitem__(self, index):\n","    inputs = self.tokenizer.encode_plus(\n","        self.text[index],self.question[index],\n","        pad_to_max_length = True,\n","        add_special_tokens = True,\n","        return_attention_mask = True,\n","        max_length = self.max_length,\n","        truncation = True,\n","    )\n","    ids = inputs[\"input_ids\"]\n","    mask = inputs[\"attention_mask\"]\n","\n","    return{\n","        \"ids\" : torch.tensor(ids, dtype = torch.long, device = cuda),\n","        \"attention_mask\" : torch.tensor(mask, dtype = torch.long, device=cuda),\n","        \"target\" : torch.tensor(self.label[index], dtype = torch.long, device=cuda),\n","    }"]},{"cell_type":"code","execution_count":57,"metadata":{"id":"_BQixoR_WCc8","executionInfo":{"status":"ok","timestamp":1641721252596,"user_tz":-420,"elapsed":312,"user":{"displayName":"Tuyen Duong Van","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjtTacBQ6s-40IAkPpB9UiqHRK4GYzu8VaLeAEr9g=s64","userId":"13283457235207767479"}}},"outputs":[],"source":["dataset = TextDataset(data['context'],data['question'],data['label'],tokenizer, 256)"]},{"cell_type":"code","execution_count":58,"metadata":{"id":"POz_cfRDWsW6","executionInfo":{"status":"ok","timestamp":1641721253897,"user_tz":-420,"elapsed":3,"user":{"displayName":"Tuyen Duong Van","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjtTacBQ6s-40IAkPpB9UiqHRK4GYzu8VaLeAEr9g=s64","userId":"13283457235207767479"}}},"outputs":[],"source":["datatrainloader = DataLoader(dataset=dataset, batch_size=16)"]},{"cell_type":"code","execution_count":59,"metadata":{"id":"H5xUn2Q1dJ1J","executionInfo":{"status":"ok","timestamp":1641721255023,"user_tz":-420,"elapsed":1,"user":{"displayName":"Tuyen Duong Van","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjtTacBQ6s-40IAkPpB9UiqHRK4GYzu8VaLeAEr9g=s64","userId":"13283457235207767479"}}},"outputs":[],"source":["class BERT(nn.Module):\n","  def __init__(self, bert):\n","    super(BERT, self).__init__()\n","    self.bert = bert\n","    self.linear_1 = nn.Linear(768*4, 128)\n","    self.linear_2 = nn.Linear(128, 2)\n","    # self.sigmoid = nn.Sigmoid()\n","  def forward(self, input_ids, attention_mask):\n","    output = self.bert(input_ids = input_ids, attention_mask = attention_mask)\n","    cls_output = torch.cat((output['hidden_states'][-1][:,0,:],\n","                            output['hidden_states'][-2][:,0,:],\n","                            output['hidden_states'][-3][:,0,:],\n","                            output['hidden_states'][-4][:,0,:]), dim = -1)\n","    output = self.linear_1(cls_output)\n","    output = self.linear_2(output)\n","    # output = self.sigmoid(output)\n","    return output"]},{"cell_type":"code","execution_count":60,"metadata":{"id":"lcJjpbgzUfZM","executionInfo":{"status":"ok","timestamp":1641721257125,"user_tz":-420,"elapsed":541,"user":{"displayName":"Tuyen Duong Van","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjtTacBQ6s-40IAkPpB9UiqHRK4GYzu8VaLeAEr9g=s64","userId":"13283457235207767479"}}},"outputs":[],"source":["model = BERT(phobert).to(cuda)\n","loss_function = nn.CrossEntropyLoss()\n","optimizer = optim.Adam(model.parameters(), lr = 1e-6)"]},{"cell_type":"code","execution_count":61,"metadata":{"id":"1le3NcRjVNyr","executionInfo":{"status":"ok","timestamp":1641721258083,"user_tz":-420,"elapsed":1,"user":{"displayName":"Tuyen Duong Van","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjtTacBQ6s-40IAkPpB9UiqHRK4GYzu8VaLeAEr9g=s64","userId":"13283457235207767479"}}},"outputs":[],"source":["for param in model.bert.parameters():\n","  param.requires_grad = False"]},{"cell_type":"code","execution_count":62,"metadata":{"id":"oysHJGEpdsXF","executionInfo":{"status":"ok","timestamp":1641721258504,"user_tz":-420,"elapsed":2,"user":{"displayName":"Tuyen Duong Van","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjtTacBQ6s-40IAkPpB9UiqHRK4GYzu8VaLeAEr9g=s64","userId":"13283457235207767479"}}},"outputs":[],"source":["transformers.logging.set_verbosity_error()"]},{"cell_type":"code","execution_count":63,"metadata":{"id":"DzkQJj5YVRxi","executionInfo":{"status":"ok","timestamp":1641724507226,"user_tz":-420,"elapsed":1048215,"user":{"displayName":"Tuyen Duong Van","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjtTacBQ6s-40IAkPpB9UiqHRK4GYzu8VaLeAEr9g=s64","userId":"13283457235207767479"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"81c44d77-8c58-45a9-d958-541e6eec905d"},"outputs":[{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["0\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["  0%|          | 0/945 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2232: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  FutureWarning,\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["1\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":[""]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["2\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":[""]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["3\n"]},{"output_type":"stream","name":"stderr","text":[""]},{"output_type":"stream","name":"stdout","text":["4\n"]},{"output_type":"stream","name":"stderr","text":[""]}],"source":["model.train()\n","for epoch in range(5):\n","  print(epoch)\n","  loop = tqdm(enumerate(datatrainloader), leave=False, total=len(datatrainloader))\n","  for batch, dl in loop:\n","    ids = dl['ids']\n","    attention_mask = dl['attention_mask']\n","    label = dl['target']\n","\n","    optimizer.zero_grad()\n","    output = model(input_ids=ids, attention_mask = attention_mask)\n","    # print(output)\n","    # print(label)\n","    # temp = torch.tensor(one_hot(label, 2),dtype=torch.float, device=cuda)\n","    loss = loss_function(output, label)\n","\n","    predict =torch.argmax(output, dim = 1)\n","    correct = sum(1 for a, b in zip(predict, label) if a == b)\n","    samples = output.shape[0]\n","    accuracy = correct/samples\n","    loss.backward()\n","    optimizer.step()\n","\n","    loop.set_description(f'Epoch={epoch}/10')\n","    loop.set_postfix(loss=loss.item(),acc=accuracy)"]},{"cell_type":"code","source":["torch.save(model.state_dict(), '/content/drive/MyDrive/Fine-Tune-Bert/model_QA_1CLS_phobert_zalo_5epoch.pth')"],"metadata":{"id":"JtGujByP1tDf","executionInfo":{"status":"ok","timestamp":1641724512123,"user_tz":-420,"elapsed":2818,"user":{"displayName":"Tuyen Duong Van","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjtTacBQ6s-40IAkPpB9UiqHRK4GYzu8VaLeAEr9g=s64","userId":"13283457235207767479"}}},"execution_count":64,"outputs":[]},{"cell_type":"code","source":["# model = BERT(phobert).to(cuda)\n","# model.load_state_dict(torch.load('/content/drive/MyDrive/Fine-Tune-Bert/model_QA_4CLS_phobert.pth'))"],"metadata":{"id":"VR_tScSO10rx"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def accuracy(datatrainloader,model):\n","  loop = tqdm(enumerate(datatrainloader), leave=False, total=len(datatrainloader))\n","  samples = 0\n","  correct = 0\n","  for batch, dl in loop:\n","    ids = dl['ids']\n","    attention_mask = dl['attention_mask']\n","    label = dl['target']\n","\n","    output = model(input_ids=ids, attention_mask = attention_mask)\n","    predict =torch.argmax(output, dim = 1)\n","\n","    temp_correct = sum(1 for a, b in zip(predict, label) if a == b)\n","    temp_samples = output.shape[0]\n","    samples += temp_samples\n","    correct += temp_correct\n","    accuracy = temp_correct/temp_samples\n","\n","    loop.set_postfix(acc=accuracy)\n","  return correct*1.0/samples"],"metadata":{"id":"IMz3WNYrg_32","executionInfo":{"status":"ok","timestamp":1641724512124,"user_tz":-420,"elapsed":8,"user":{"displayName":"Tuyen Duong Van","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjtTacBQ6s-40IAkPpB9UiqHRK4GYzu8VaLeAEr9g=s64","userId":"13283457235207767479"}}},"execution_count":65,"outputs":[]},{"cell_type":"code","source":["print(accuracy(datatrainloader,model))"],"metadata":{"id":"txdcdSwyhzad","executionInfo":{"status":"ok","timestamp":1641725157843,"user_tz":-420,"elapsed":645726,"user":{"displayName":"Tuyen Duong Van","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjtTacBQ6s-40IAkPpB9UiqHRK4GYzu8VaLeAEr9g=s64","userId":"13283457235207767479"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"4336faab-efe3-42e3-9d75-bc9660449905"},"execution_count":66,"outputs":[{"output_type":"stream","name":"stderr","text":["\r  0%|          | 0/945 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2232: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  FutureWarning,\n","                                                           "]},{"output_type":"stream","name":"stdout","text":["0.701085517606566\n"]},{"output_type":"stream","name":"stderr","text":["\r"]}]},{"cell_type":"markdown","source":["#Evaluate in Test Set"],"metadata":{"id":"wUBnMcqjkVEI"}},{"cell_type":"code","source":["model = BERT(phobert).to(cuda)\n","model.load_state_dict(torch.load('/content/drive/MyDrive/Fine-Tune-Bert/model_QA_1CLS_phobert_zalo_5epoch.pth'))"],"metadata":{"id":"rkla4QqTkS0o","executionInfo":{"status":"ok","timestamp":1641725296394,"user_tz":-420,"elapsed":1294,"user":{"displayName":"Tuyen Duong Van","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjtTacBQ6s-40IAkPpB9UiqHRK4GYzu8VaLeAEr9g=s64","userId":"13283457235207767479"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"bff44dd5-cf61-4efc-baa6-9c1e7fa3794f"},"execution_count":68,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<All keys matched successfully>"]},"metadata":{},"execution_count":68}]},{"cell_type":"code","source":["testset = pd.read_json('/content/drive/MyDrive/Fine-Tune-Bert/data/testing_zalodata.json')"],"metadata":{"id":"aicssTp6kl1g","executionInfo":{"status":"ok","timestamp":1641725297119,"user_tz":-420,"elapsed":437,"user":{"displayName":"Tuyen Duong Van","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjtTacBQ6s-40IAkPpB9UiqHRK4GYzu8VaLeAEr9g=s64","userId":"13283457235207767479"}}},"execution_count":69,"outputs":[]},{"cell_type":"code","source":["testset.shape"],"metadata":{"id":"b00tQk2Oktu_","executionInfo":{"status":"ok","timestamp":1641725297513,"user_tz":-420,"elapsed":3,"user":{"displayName":"Tuyen Duong Van","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjtTacBQ6s-40IAkPpB9UiqHRK4GYzu8VaLeAEr9g=s64","userId":"13283457235207767479"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"81cf8e0e-4057-42b9-d26d-12544f3b4921"},"execution_count":70,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(3000, 5)"]},"metadata":{},"execution_count":70}]},{"cell_type":"code","source":["testset = testset.rename({'text':'context'}, axis = 1)"],"metadata":{"id":"Bb10XCS2k13g","executionInfo":{"status":"ok","timestamp":1641725298707,"user_tz":-420,"elapsed":4,"user":{"displayName":"Tuyen Duong Van","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjtTacBQ6s-40IAkPpB9UiqHRK4GYzu8VaLeAEr9g=s64","userId":"13283457235207767479"}}},"execution_count":71,"outputs":[]},{"cell_type":"code","source":["columns = [\"context\", 'question','label']\n","data = []\n","for index, row in testset.iterrows():\n","  temp = []\n","  temp.append(row['context'])\n","  temp.append(row['question'])\n","  temp.append(int(row['label']))\n","  data.append(temp)\n","data = pd.DataFrame(data, columns=columns)"],"metadata":{"id":"U2t4k0RSlHqd","executionInfo":{"status":"ok","timestamp":1641725300084,"user_tz":-420,"elapsed":451,"user":{"displayName":"Tuyen Duong Van","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjtTacBQ6s-40IAkPpB9UiqHRK4GYzu8VaLeAEr9g=s64","userId":"13283457235207767479"}}},"execution_count":72,"outputs":[]},{"cell_type":"code","source":["tx = TextDataset(data['context'][0:3000],data['question'][0:3000],data['label'][0:3000],tokenizer, 256)"],"metadata":{"id":"Ic9GtlcYllT-","executionInfo":{"status":"ok","timestamp":1641725451146,"user_tz":-420,"elapsed":290,"user":{"displayName":"Tuyen Duong Van","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjtTacBQ6s-40IAkPpB9UiqHRK4GYzu8VaLeAEr9g=s64","userId":"13283457235207767479"}}},"execution_count":76,"outputs":[]},{"cell_type":"code","source":["dl = DataLoader(dataset=tx, batch_size=128)"],"metadata":{"id":"QA5KFq6wlOyV","executionInfo":{"status":"ok","timestamp":1641725452400,"user_tz":-420,"elapsed":326,"user":{"displayName":"Tuyen Duong Van","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjtTacBQ6s-40IAkPpB9UiqHRK4GYzu8VaLeAEr9g=s64","userId":"13283457235207767479"}}},"execution_count":77,"outputs":[]},{"cell_type":"code","source":["print(accuracy(dl,model))"],"metadata":{"id":"at1dl0CDlVvz","executionInfo":{"status":"ok","timestamp":1641725573441,"user_tz":-420,"elapsed":119997,"user":{"displayName":"Tuyen Duong Van","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjtTacBQ6s-40IAkPpB9UiqHRK4GYzu8VaLeAEr9g=s64","userId":"13283457235207767479"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"5c0d8807-bb6f-45da-b02e-c1bb8741b75a"},"execution_count":78,"outputs":[{"output_type":"stream","name":"stderr","text":["\r  0%|          | 0/24 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2232: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  FutureWarning,\n","                                                          "]},{"output_type":"stream","name":"stdout","text":["0.593\n"]},{"output_type":"stream","name":"stderr","text":["\r"]}]},{"cell_type":"markdown","source":["#Demo"],"metadata":{"id":"HROuQMJF5kyM"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"Q-Lb8otb5hDO"},"outputs":[],"source":["line = \"Tôi là sinh_viên trường đại_học Công_nghệ .\"\n","\n","input_ids = torch.tensor([tokenizer.encode(line)])\n","\n","with torch.no_grad():\n","    features = phobert(input_ids)  # Models outputs are now tuples\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"WVzETepH5hDO"},"outputs":[],"source":["features.keys()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"HkjrOCNx5hDO"},"outputs":[],"source":["features['hidden_states'][-1][:,0,:].shape"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"fLh5JMgl5hDO"},"outputs":[],"source":["torch.cat((features['hidden_states'][-1][:,0,:],\n","           features['hidden_states'][-2][:,0,:],\n","           features['hidden_states'][-3][:,0,:],\n","           features['hidden_states'][-4][:,0,:]), dim = -1).shape"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"HuxkqWVFZIUu"},"outputs":[],"source":["features.keys()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jtnmDSlSl2Iy"},"outputs":[],"source":["features['hidden_states'][-1][:,0,:].shape"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"BK3sNKOZTqxM"},"outputs":[],"source":["torch.cat((features['hidden_states'][-1][:,0,:],\n","           features['hidden_states'][-2][:,0,:],\n","           features['hidden_states'][-3][:,0,:],\n","           features['hidden_states'][-4][:,0,:]), dim = -1).shape"]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":[],"name":"question_answer.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}